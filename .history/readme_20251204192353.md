# Customer Churn Prediction ML Pipeline

![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)
![ML](https://img.shields.io/badge/ML-Scikit--learn-orange.svg)
![Status](https://img.shields.io/badge/Status-Week%202%20Complete-success.svg)

An end-to-end production-ready machine learning system for predicting customer churn in telecommunications. Demonstrates enterprise-grade data engineering, model development, and MLOps practices.

## ğŸ¯ Project Overview

This project showcases a complete ML workflow from raw data to trained models:

- **Data Engineering**: Robust ETL pipeline with validation and logging
- **Feature Engineering**: Advanced feature creation, encoding, and scaling
- **Model Development**: Multiple algorithms (Logistic Regression, Random Forest, XGBoost)
- **Model Evaluation**: Comprehensive metrics and comparison framework
- **Code Quality**: Modular design, type hints, documentation

## ğŸ“Š Results

| Model | Accuracy | Precision | Recall | F1 Score | ROC-AUC |
|-------|----------|-----------|--------|----------|---------|
| Logistic Regression | 0.8043 | 0.6712 | 0.5483 | 0.6034 | 0.8475 |
| Random Forest | 0.7938 | 0.6416 | 0.5107 | 0.5685 | 0.8347 |
| **XGBoost** | **0.8099** | **0.6877** | **0.5537** | **0.6136** | **0.8527** |

**Best Model**: XGBoost with F1 score of 0.6136

## ğŸ—ï¸ Architecture
```
â”œâ”€â”€ data/                   # Data storage
â”‚   â”œâ”€â”€ telco_churn_raw.csv        # Original dataset
â”‚   â”œâ”€â”€ telco_churn_clean.csv      # Cleaned data
â”‚   â””â”€â”€ telco_churn_features.csv   # Processed features
â”œâ”€â”€ notebooks/              # Analysis notebooks
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb
â”‚   â””â”€â”€ 02_model_analysis.ipynb
â”œâ”€â”€ src/                    # Source code
â”‚   â”œâ”€â”€ data_pipeline.py           # Data cleaning & validation
â”‚   â”œâ”€â”€ feature_engineering.py     # Feature creation & transformation
â”‚   â””â”€â”€ model_training.py          # Model training & evaluation
â”œâ”€â”€ models/                 # Trained models & metrics
â”‚   â”œâ”€â”€ logistic_regression.joblib
â”‚   â”œâ”€â”€ random_forest.joblib
â”‚   â”œâ”€â”€ xgboost.joblib
â”‚   â””â”€â”€ *_metrics.json
â””â”€â”€ tests/                  # Unit tests (coming in Week 3)
```

## ğŸ› ï¸ Tech Stack

**Core ML/Data:**
- Python 3.10+
- Pandas, NumPy
- Scikit-learn
- XGBoost

**Development:**
- Jupyter Notebooks
- Git/GitHub

**Coming in Week 3:**
- FastAPI (REST API)
- Docker (Containerization)
- Pytest (Testing)

## ğŸš€ Getting Started

### Prerequisites
- Python 3.10 or higher
- pip

### Installation
```bash
# Clone repository
git clone https://github.com/yamylemerleremond/customer-churn-ml-pipeline.git
cd customer-churn-ml-pipeline

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### Usage

**Run complete pipeline:**
```bash
# 1. Clean data
python src/data_pipeline.py

# 2. Engineer features
python src/feature_engineering.py

# 3. Train models
python src/model_training.py
```

**Explore in notebooks:**
```bash
jupyter notebook
# Open notebooks/02_model_analysis.ipynb
```

## ğŸ“ˆ Key Features

### Data Pipeline
- Automated data validation and quality checks
- Robust error handling and logging
- Efficient data transformations

### Feature Engineering
- Tenure-based customer segmentation
- Service usage scoring
- Interaction features between contract types and payment methods
- Proper handling of categorical variables with label encoding
- Feature scaling for numerical variables

### Model Training
- Multiple algorithm comparison
- Stratified train-test split
- Class imbalance handling
- Cross-validation ready
- Comprehensive evaluation metrics

### Analysis & Visualization
- ROC curve comparison
- Feature importance analysis
- Confusion matrix visualization
- Performance metrics dashboard

## ğŸ“ Progress Log

### âœ… Week 1 (Completed)
- Project setup and structure
- Data loading and exploration
- Data cleaning pipeline with validation
- Initial EDA with visualizations

### âœ… Week 2 (Completed)
- Feature engineering pipeline
- Model training framework
- Three models trained and evaluated
- Comprehensive model analysis
- Performance comparison and visualization

### ğŸš§ Week 3 (Next)
- REST API with FastAPI
- Model serving endpoint
- Docker containerization
- API documentation

### ğŸ¯ Week 4 (Planned)
- Unit and integration tests
- Performance optimization
- CI/CD setup
- Final documentation

## ğŸ’¡ Technical Highlights

**Enterprise Experience Applied:**
- Data pipeline design mirrors enterprise ETL systems
- Logging and validation patterns from production systems
- Modular architecture for maintainability
- Performance-conscious implementation

**ML Best Practices:**
- Proper train-test split with stratification
- Feature engineering before model training
- Multiple models for comparison
- Comprehensive evaluation metrics
- Clear documentation of decisions

## ğŸ“ Background

Built as part of my transition from enterprise integration architecture (Salesforce, ETL, APIs) to ML/AI engineering. This project demonstrates how 25+ years of technical problem-solving and system design applies to modern ML workflows.

## ğŸ“« Contact

- GitHub: [@yamylemerleremond](https://github.com/yamylemerleremond)
- LinkedIn: [Your LinkedIn]
- Email: [Your Email]

## ğŸ“„ License

MIT License - feel free to use this code for learning or your own projects.

---

**Status**: Week 2 Complete | **Next**: Building REST API for model serving